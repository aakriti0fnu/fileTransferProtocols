**Libraries**

- http is a package included in the Python Standard Library. Its documentation can be found here: <https://docs.python.org/3/library/http.html>.  Two modules in the package are http.client and http.server.

   - **HTTP client: http.client**

        Http.client is a low-level library that implements an HTTP protocol client and is included in the Python Standard library. It defines classes that implement that client side of the HTTP and HTTPS protocols. For example, it includes a few different connection classes that represent transactions with the web server, and an HTTP response class. It is included in the Python Standard Library, and its documentation can be found here: <https://docs.python.org/3/library/http.client.html#module-http.client>. 

   - **HTTP server: http.server**

        Http.server is a library that defines classes for implementing web servers using the HTTP protocol. It includes multiple base server classes and multiple request handler classes. It is included in the Python Standard Library, and its documentation can be found here: <https://docs.python.org/3/library/http.server.html#module-http.server>. 

- **SMTP client: smtplib**

    The smtplib library implements an SMTP client session that can send mail to an SMTP server (a machine running a SMTP listener daemon). Source: library is already included in the Python Standard Library, and the documentation is here: <https://docs.python.org/3/library/smtplib.html>. 

- **SMTP server: aiosmtpd (asyncio)**

    Aiosmptd is dependent on asyncio. Thus, the latter is first described, then the former.

    The asyncio library provides functionality to write code which can execute concurrently. Thus, it is used for multiple asynchronous networking applications (e.g. servers)  including SMTP through aiosmtpd. Asyncio, as the name suggests, is particularly useful for applications with a lot of I/O. Source: this library is already included in the Python Standard Library, and the documentation is here: <https://docs.python.org/3/library/asyncio.html>. 

    Aiosmtpd is an asynchronous I/O library, based on the asyncio library,  that implements the SMTP and LMTP protocols. Source: This library can be installed as usual using pip. Simply run the command ‘pip install aiosmtpd’. Pip is the package installer for Python, it can be found here: <https://github.com/pypa/pip>. Alternatively, you can get it right from the Github (<https://github.com/aio-libs/aiosmtpd>). The documentation for aiosmtpd can be found here: <https://aiosmtpd.readthedocs.io/en/latest/>.

- **FTP client: ftplib**

    The ftplib module implements  the client portion of the FTP protocol. It defines the FTP class and FTPS class used to automate FTP tasks. It is part of the Python Standard Library, and its documentation can be found here:  <https://docs.python.org/3/library/ftplib.html>. 

- **FTP server: pyftpdlib**

    Pyftpdlib is a fast, asynchronous FTP server library. Like aiomstpd above, you can install it with pip using the command ‘pip install pyftpdlib’, or you can download it from its Github page (<https://github.com/giampaolo/pyftpdlib>), then run the setup.py script, the run the ‘install’ command. Its documentation can be found here: <https://pypi.org/project/pyftpdlib/>.  

- **BitTorrent: libtorrent, pytorrent, & pieces**

    Libtorrent is a fully complete C++ implementation of the BitTorrent protocol. Its reference documentation can be found here: <https://libtorrent.org/single-page-ref.html>, and installation instructions here: <https://libtorrent.org/building.html>. Libtorrent has a Python binding (wrapper). The installation instructions for the Python binding, and a small amount of documentation, can be found here: <https://libtorrent.org/python_binding.html#using-libtorrent-in-python>. 

    Pytorrent is a BitTorrent client tool. You can download it from its Github page (<https://github.com/gallexis/pytorrent>). It does not have documentation.

    Pieces is also a BitTorrent client implementation, based on the asyncio library. It can be downloaded from its Github page: (<https://github.com/eliasson/pieces>), which features a small amount of documentation. 

**Experimental Observations and Discussion**

- On the largest file (10MB), FTP performed the best with an average of 81,000 kbps. Comparatively, HTTP does not perform too bad, with an average of 66,000 kbps. However, the standard deviation for FTP is only 5,000 kbps, whereas the standard deviation for HTTP was 23,000 kbps. Thus, not only is FTP more efficient for the 10MB file, but it is also more reliable. A similar argument can be made for the 1MB file; FTP had an average of 51,000 kbps, whereas HTTP had an average of 52,000 kbps. These are essentially equal throughput rates. However, FTP had a standard deviation of 7,000 kbps, whreast HTTP and a standard deviation of 19,000 kbps. Thus, FTP would also be the preferred protocol for a 1MB file, since it is just as efficient as HTTP but is more reliable. If  we were to use HTTP to download chunks of a large file in parallel, however, it would probably have a higher throughput than FTP. FTP’s primary advantage comes from a lack of meta-data in the packets; just the file binary is sent in the FTP-DATA packets after the control channel is established. HTTP has this advantage, too, after the GET request, but it can support other formats besides binary, e.g. ASCII.

- This pattern between FTP and HTTP does not hold for the smaller file of 100kB. FTP had a throughput of 18,000 kbps with a standard deviation of 4,000 kbps, whereas HTTP had a much higher average of 46,000 kbps and an extremely high standard deviation of 23,000 kbps. For the smallest file of only 10kB, however, we see that HTTP is much faster than FTP. The throughput of FTP was 4,000 kbps with a standard deviation of 900 kbps, whereas HTTP had an average of 280,000 kbps and a standard deviation of 50,000 kbps. Two properties of the HTTP protocol likely contribute to its greater throughput when requesting small files. First, HTTP can reuse persistent connection(s), lowering the communication time overhead compared to FTP, which will need to send FTP packets on port 21 to establish the connection each time it requests a file (each time FTP-DATA packets need to be  sent on port 22). Additionally, HTTP can get multiple files much faster than FTP due to pipelining. This means that the client can request the next file before the previous file transfer of the previous request has finished. FTP will not pipeline the data transfers. Simply put, HTTP is more responsive for the massive amount of requests (and response) for many small files. Thus, this effect was particularly pronounced when we requested this smallest file 10,000 times. Note that it is possible for FTP to request multiple files to be parallely transferred with the same control channel/connection (it can use the same FTP control packet to get FTP-DATA packets from different files), but this requires server-side support for the request, which is often not present. It also requires a distinct TCP connection for each transfer whereas HTTP does not.

- We also see that, on the right side of our results table, that both FTP and HTTP do not have an application layer data overhead. That is, the total amount of HTTP and FTP application layer data in the packets that contain part of the file as the application layer payload is equal to the total data for the part/segment of the file. Both FTP and HTTP do have some application layer data overhead if we consider the packets needed to establish the connection, ACK, and tear down the connection. However, during actual file transfer, the only application layer data in the packets are the file data. This was confirmed in Wireshark, where we saw that for both FTP and HTTP, all bytes were file bytes. We sent a test .txt file containing some text, and the first byte in the application layer data was the first byte of the text in the file. In other words, the byte *before* the first byte of the file/file segment was part of the TCP/transport layer PDU (segment), *not* part of the application layer data encapsulated inside the TCP segment.

- The throughput for file transfers using SMTP was much lower than FTP or HTTP. For any file size, it is not necessary to consider SMTP as an option to send the files. For the 10MB file and the 1MB file, its throughput was 3,500 kbps. In other words, SMTP’s throughput was only ~3% of FTP’s and ~4% of HTTP’s for the 10MB file, and ~7% of both FTP’s and HTTP’s throughput for the 1MB file. For the 100kB file and the 10kB file, SMTP’s throughput was 3,000 kbps and 1,400 kbps, respectively. One reason why SMTP has a much lower throughput than FTP or HTTP for the file transfers is that it only supports 7-bit ASCII, which obviously is much slower regarding I/O than binary formatting. If the file is not already in 7-bit ASCII, it needs to be encoded, then decoded, increasing overall transfer time. Like HTTP, SMTP can use persistent connections. Unlike HTTP or FTP, we see from our results table that SMTP has comparatively quite a bit of application layer data overhead. Regarding the 10MB, 1MB, and 100kB files, SMTP had a data overhead of 37% (the ratio of total application layer data transferred to the size of the file transferred was 1.37). Likewise, for the 10kB file, the overhead was 27%. A quick packet analysis reveals why the total bytes of data transferred is so much higher than the total file size. Unlike FTP or HTTP, each SMTP segment containing distinct file chunks has a considerable amount of application layer data (consisting of email meta-data such as the email addresses) encapsulated inside the TCP segment before the start of the file chunk’s data. Note that I did not create an email subject or email body to keep the overhead as low as possible.  

- Since BitTorrent is a P2P protocol, its primary advantage comes from distributing a file from a server to a *large* number of clients. Since I was unable to perform the BitTorrent experiment, I am unable to determine if three clients, per the instructions, is sufficient to have a throughput greater than the other protocols or not. However, as many peers are added, BitTorrent will see throughput advantages compared to a classic client-server model with many clients since it will avoid the bottleneck of the server bandwidth. In other words, as more peers are added to the BitTorrent network, the minimum distribution time of the file decreases, thus the throughput increases compared to the client-server protocols (HTTP, FTP, and SMTP). With many clients, a client-server model’s file distribution time is the number of clients, multiplied by the file size, divided by the server’s upload/output rate. Since under the BitTorrent protocol, the clients help the server distribute the file, there exists a number of clients large enough to allow BitTorrent to have a higher throughput than any of the previous protocols. In other words, file distribution time increases linearly with the number of clients in a client-server mode. Using BitTorrent, however, file distribution time increases in a log fashion and quickly reaches an upper bound as the number of clients grow. So far I have been talking about the time it takes for the P2P and client-server protocols to distribute the file to *all*  the clients. For the clients served earliest by the server in the client-server model, throughput will seem much higher to those clients compared to BitTorrent. 

- Regarding overhead, the typical file chunk size in a given BitTorrent packet is 256 kB. From this, I can speculate that even with just one client, BitTorrent will have throughput comparable to the other protocols for the small files of 10 kB and 100 kB.  Regardless of the application layer data overhead, BitTorrent does experience more communication and computation overhead compared to the other protocols due to its P2P nature. For example, peers need to process the list of peers from the tracker, ask peers for the file chunks they have, process those responses using the ‘rarest first’ technique, determine which requests from other peers to respond to (typically the peers providing data to the given peer at the highest rate, which needs to be calculated,  i.e. unchoked peers), etc. Lastly, like FTP and HTTP, BitTorrent will have an application layer data overheard, close to 0%. So its entries in the results table (total application layer data size / file size) are thus provided as 1. This is because BitTorrent has 13 bytes of application layer data that is not part of the file per file chunk packet. If we assume a typical file chunk size of 256kB, the overhead is 0.005%. I was not able to view this in Wireshark as the application layer data is encrypted in BitTorrent. However, it is know that the 13 bytes of application layer data that are not part of the file chunk are the meta-data for: length (4 bytes), messageID (1 byte), the piece index in the torrent (4 bytes), and the current piece’s offset (4 bytes).

**References**

- Edgeworth, Brad, et al. CCNP and CCIE Enterprise Core: ENCOR 350-401. Cisco Press, 2020.

- Kurose, James F., and Keith W. Ross. *Computer Networking: A Top-down Approach*. 7th ed., Pearson, 2017.

- Meyers, Mike. CompTIA Network+ Certification Exam Guide: Exam N10-007. 7th ed.,      McGraw-Hill, 2018.
